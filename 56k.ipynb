{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDc54MbLlzejtcT3NAILSt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccastano1997/version3.1/blob/main/56k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op4yR7clgN3i",
        "outputId": "77dde5df-3c14-4075-b452-a8f9c7371373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Dec 4th scores and added Dec 5th games.\n",
            "            Date   Time              Home Team               Away Team  \\\n",
            "290  04 Dec 2025  19:30        Toronto Raptors      Los Angeles Lakers   \n",
            "291  04 Dec 2025  19:30          Brooklyn Nets               Utah Jazz   \n",
            "292  04 Dec 2025  20:00   New Orleans Pelicans  Minnesota Timberwolves   \n",
            "293  05 Dec 2025  19:00         Boston Celtics      Los Angeles Lakers   \n",
            "294  05 Dec 2025  19:00          Orlando Magic              Miami Heat   \n",
            "295  05 Dec 2025  19:30          Atlanta Hawks          Denver Nuggets   \n",
            "296  05 Dec 2025  19:30    Cleveland Cavaliers       San Antonio Spurs   \n",
            "297  05 Dec 2025  19:30        Detroit Pistons  Portland Trail Blazers   \n",
            "298  05 Dec 2025  19:30        New York Knicks               Utah Jazz   \n",
            "299  05 Dec 2025  19:30      Charlotte Hornets         Toronto Raptors   \n",
            "300  05 Dec 2025  20:00          Chicago Bulls          Indiana Pacers   \n",
            "301  05 Dec 2025  20:00        Houston Rockets            Phoenix Suns   \n",
            "302  05 Dec 2025  20:00      Memphis Grizzlies    Los Angeles Clippers   \n",
            "303  05 Dec 2025  20:00        Milwaukee Bucks      Philadelphia 76ers   \n",
            "304  05 Dec 2025  21:30  Oklahoma City Thunder        Dallas Mavericks   \n",
            "\n",
            "       Score Home Odds Away Odds  Bookmakers  \n",
            "290  120-123      -139      +117           5  \n",
            "291  110-123      +167      -200           6  \n",
            "292  116-125      +437      -625           6  \n",
            "293               -250      +200           6  \n",
            "294               -208      +171           6  \n",
            "295               +199      -244           6  \n",
            "296               -196      +164           6  \n",
            "297               -303      +240           6  \n",
            "298              -1250      +705           6  \n",
            "299               -312      +244           5  \n",
            "300               -196      +163           6  \n",
            "301               -556      +399           6  \n",
            "302               +106      -127           6  \n",
            "303               +104      -123           6  \n",
            "304              -1111      +684           6  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Load the file\n",
        "df = pd.read_csv(\"nba_odds_full.csv\")\n",
        "\n",
        "# 2. Define the updates for Dec 4th (Scores found in the previous images/PDF)\n",
        "# Format in CSV is \"HomeScore-AwayScore\" based on existing data like \"129-126\"\n",
        "dec4_updates = {\n",
        "    \"Washington Wizards\": \"101-146\",\n",
        "    \"Philadelphia 76ers\": \"99-98\",\n",
        "    \"Toronto Raptors\": \"120-123\",\n",
        "    \"Brooklyn Nets\": \"110-123\",\n",
        "    \"New Orleans Pelicans\": \"116-125\"\n",
        "}\n",
        "\n",
        "# 3. Update the rows\n",
        "# We iterate through the updates and apply them to the rows matching Date=\"04 Dec 2025\" and Home Team\n",
        "for home_team, score in dec4_updates.items():\n",
        "    mask = (df['Date'] == '04 Dec 2025') & (df['Home Team'] == home_team)\n",
        "    df.loc[mask, 'Score'] = score\n",
        "\n",
        "# 4. Append Dec 5th Games (Since they were missing in the .tail() output)\n",
        "# Data from page8.pdf\n",
        "dec5_games = [\n",
        "    [\"05 Dec 2025\", \"19:00\", \"Boston Celtics\", \"Los Angeles Lakers\", \"\", \"-250\", \"+200\", 6],\n",
        "    [\"05 Dec 2025\", \"19:00\", \"Orlando Magic\", \"Miami Heat\", \"\", \"-208\", \"+171\", 6],\n",
        "    [\"05 Dec 2025\", \"19:30\", \"Atlanta Hawks\", \"Denver Nuggets\", \"\", \"+199\", \"-244\", 6],\n",
        "    [\"05 Dec 2025\", \"19:30\", \"Cleveland Cavaliers\", \"San Antonio Spurs\", \"\", \"-196\", \"+164\", 6],\n",
        "    [\"05 Dec 2025\", \"19:30\", \"Detroit Pistons\", \"Portland Trail Blazers\", \"\", \"-303\", \"+240\", 6],\n",
        "    [\"05 Dec 2025\", \"19:30\", \"New York Knicks\", \"Utah Jazz\", \"\", \"-1250\", \"+705\", 6],\n",
        "    [\"05 Dec 2025\", \"19:30\", \"Charlotte Hornets\", \"Toronto Raptors\", \"\", \"-312\", \"+244\", 5],\n",
        "    [\"05 Dec 2025\", \"20:00\", \"Chicago Bulls\", \"Indiana Pacers\", \"\", \"-196\", \"+163\", 6],\n",
        "    [\"05 Dec 2025\", \"20:00\", \"Houston Rockets\", \"Phoenix Suns\", \"\", \"-556\", \"+399\", 6],\n",
        "    [\"05 Dec 2025\", \"20:00\", \"Memphis Grizzlies\", \"Los Angeles Clippers\", \"\", \"+106\", \"-127\", 6],\n",
        "    [\"05 Dec 2025\", \"20:00\", \"Milwaukee Bucks\", \"Philadelphia 76ers\", \"\", \"+104\", \"-123\", 6],\n",
        "    [\"05 Dec 2025\", \"21:30\", \"Oklahoma City Thunder\", \"Dallas Mavericks\", \"\", \"-1111\", \"+684\", 6]\n",
        "]\n",
        "\n",
        "# Check if Dec 5 is already there to avoid duplicates\n",
        "if not df['Date'].str.contains('05 Dec 2025').any():\n",
        "    new_df = pd.DataFrame(dec5_games, columns=df.columns)\n",
        "    df = pd.concat([df, new_df], ignore_index=True)\n",
        "\n",
        "# 5. Save the fixed file\n",
        "df.to_csv(\"nba_odds_full.csv\", index=False)\n",
        "\n",
        "print(\"Updated Dec 4th scores and added Dec 5th games.\")\n",
        "print(df.tail(15)) # Verify the end of the file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nba_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1VeeQZThSCV",
        "outputId": "8c10ae26-c8bc-4e27-e4e5-e3c0c7f351a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nba_api\n",
            "  Downloading nba_api-1.11.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from nba_api) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from nba_api) (2.2.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from nba_api) (2.32.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nba_api) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nba_api) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nba_api) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2025.11.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->nba_api) (1.17.0)\n",
            "Downloading nba_api-1.11.3-py3-none-any.whl (318 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/319.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m317.4/319.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.0/319.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nba_api\n",
            "Successfully installed nba_api-1.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#==========================================\n",
        "# üèÄ NBA PREDICTION MODEL V3.0 (Advanced)\n",
        "# ==========================================\n",
        "# Features: LSTM Neural Network, Four Factors Analytics, Live Odds, Injury Audit\n",
        "# ==========================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from nba_api.stats.endpoints import leaguegamefinder, leaguedashplayerstats\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "SEASON = '2025-26'\n",
        "SEQ_LENGTH = 5  # Games to look back\n",
        "ODDS_FILE = 'nba_odds_full.csv'\n",
        "\n",
        "# ==========================================\n",
        "# 1. LOAD AND PROCESS ODDS DATA\n",
        "# ==========================================\n",
        "print(f\"--- STEP 1: Loading Betting Data ({ODDS_FILE}) ---\")\n",
        "try:\n",
        "    odds_df = pd.read_csv(ODDS_FILE)\n",
        "    odds_df['Date'] = pd.to_datetime(odds_df['Date'], format='%d %b %Y')\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Error: '{ODDS_FILE}' not found. Please upload it.\")\n",
        "    raise\n",
        "\n",
        "# Convert American Odds to Implied Probability\n",
        "def american_to_prob(odd_str):\n",
        "    try:\n",
        "        if pd.isna(odd_str) or odd_str == 'v': return 0.5\n",
        "        odd = float(odd_str)\n",
        "        if odd > 0: return 100 / (odd + 100)\n",
        "        else: return abs(odd) / (abs(odd) + 100)\n",
        "    except: return 0.5\n",
        "\n",
        "odds_df['Home_Prob'] = odds_df['Home Odds'].apply(american_to_prob)\n",
        "odds_df['Away_Prob'] = odds_df['Away Odds'].apply(american_to_prob)\n",
        "\n",
        "# Split Training (Past Results) vs Prediction (Tonight)\n",
        "train_odds = odds_df[odds_df['Score'] != 'v'].copy()\n",
        "# Handles 'v', empty strings, or NaN (Empty cells)\n",
        "predict_odds = odds_df[odds_df['Score'].isna() | (odds_df['Score'] == 'v') | (odds_df['Score'] == '')].copy()\n",
        "print(f\"‚úÖ Loaded {len(train_odds)} past games for training.\")\n",
        "print(f\"‚úÖ Found {len(predict_odds)} games to predict tonight.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgOZzuvVxoED",
        "outputId": "48140ddb-7d54-45c9-a475-1230aa58a885"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STEP 1: Loading Betting Data (nba_odds_full.csv) ---\n",
            "‚úÖ Loaded 305 past games for training.\n",
            "‚úÖ Found 12 games to predict tonight.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "\n",
        "def get_live_injury_report():\n",
        "    print(\"üè• Scrapping Live Injury Report...\")\n",
        "    url = \"https://www.espn.com/nba/injuries\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        dfs = pd.read_html(io.StringIO(response.text))\n",
        "\n",
        "        injured_stars = {}\n",
        "\n",
        "        # ESPN tables are grouped by Team. We iterate through them.\n",
        "        for df in dfs:\n",
        "            # Clean the table\n",
        "            if df.empty or len(df.columns) < 2: continue\n",
        "            df.columns = ['NAME', 'STATUS', 'REASON'] # Standardize\n",
        "\n",
        "            # Filter for \"OUT\" or \"DOUBTFUL\"\n",
        "            # You can adjust this list to include \"Day-To-Day\" if you want to be cautious\n",
        "            out_players = df[df['STATUS'].str.contains('Out|Doubtful|Questionable', case=False, na=False)]\n",
        "\n",
        "            for _, row in out_players.iterrows():\n",
        "                player_name = row['NAME']\n",
        "                status = row['STATUS']\n",
        "\n",
        "                # OPTIONAL: Filter for only \"Stars\" (Players > 20 PPG or high usage)\n",
        "                # For now, we capture everyone, but you can add a filter here.\n",
        "                # impact_score = get_player_war(player_name) # Assuming you have a WAR function\n",
        "                # if impact_score > 5.0:\n",
        "\n",
        "                # We need to map the player to their Team.\n",
        "                # (Simple way: store them in a list and fuzzy match later)\n",
        "                injured_stars[player_name] = status\n",
        "\n",
        "        print(f\"‚úÖ Found {len(injured_stars)} active injuries.\")\n",
        "        return injured_stars\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Injury Scrape Failed: {e}\")\n",
        "        return {}"
      ],
      "metadata": {
        "id": "9ajpTJCS6y9_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nba_api.stats.endpoints import teamgamelog, playergamelog\n",
        "import time\n",
        "\n",
        "def calculate_team_resilience(team_name, player_name, season='2025-26'):\n",
        "    # 1. Get Team ID and Player ID (You need a helper for this mapping)\n",
        "    team_id = get_team_id(team_name)\n",
        "    player_id = get_player_id(player_name)\n",
        "\n",
        "    if not team_id or not player_id: return None\n",
        "\n",
        "    # 2. Fetch Logs\n",
        "    # (Add time.sleep to be polite to API)\n",
        "    time.sleep(0.5)\n",
        "    t_log = teamgamelog.TeamGameLog(team_id=team_id, season=season).get_data_frames()[0]\n",
        "    time.sleep(0.5)\n",
        "    p_log = playergamelog.PlayerGameLog(player_id=player_id, season=season).get_data_frames()[0]\n",
        "\n",
        "    # 3. Find Games WITHOUT the Player\n",
        "    games_with_player = set(p_log['Game_ID'])\n",
        "    games_without = t_log[~t_log['Game_ID'].isin(games_with_player)]\n",
        "\n",
        "    if games_without.empty:\n",
        "        return {\"status\": \"Unknown\", \"record\": \"0-0\", \"win_pct\": 0.0}\n",
        "\n",
        "    # 4. Calculate Win %\n",
        "    wins = len(games_without[games_without['WL'] == 'W'])\n",
        "    losses = len(games_without[games_without['WL'] == 'L'])\n",
        "    total = wins + losses\n",
        "    win_pct = wins / total\n",
        "\n",
        "    # 5. Classify\n",
        "    status = \"Neutral\"\n",
        "    if win_pct > 0.60: status = \"Resilient\"  # e.g., Lakers 3-1\n",
        "    elif win_pct < 0.30: status = \"Dependent\" # e.g., Hawks 0-4\n",
        "\n",
        "    print(f\"   üìä Analysis: {team_name} are {wins}-{losses} without {player_name}\")\n",
        "    return {\"status\": status, \"record\": f\"{wins}-{losses}\", \"win_pct\": win_pct}"
      ],
      "metadata": {
        "id": "W7tgB7xT7abW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_live_resilience_map(games_tonight):\n",
        "    print(\"\\n--- ü§ñ BUILDING LIVE RESILIENCE MAP ---\")\n",
        "\n",
        "    # 1. Get Injuries\n",
        "    injuries = get_live_injury_report() # From Step 1\n",
        "\n",
        "    resilience_map = {}\n",
        "\n",
        "    # 2. Check only teams playing TONIGHT\n",
        "    for game in games_tonight:\n",
        "        for team in [game['Home Team'], game['Away Team']]:\n",
        "\n",
        "            # Find star players for this team who are injured\n",
        "            # (You need a roster list to match \"Luka Doncic\" to \"Lakers\")\n",
        "            team_stars = get_team_stars(team) # e.g., ['Luka Doncic', 'LeBron James']\n",
        "\n",
        "            for star in team_stars:\n",
        "                if star in injuries:\n",
        "                    print(f\"‚ö†Ô∏è Checking Impact: {star} is {injuries[star]} for {team}...\")\n",
        "\n",
        "                    # 3. Run the \"Ewing Calculation\"\n",
        "                    data = calculate_team_resilience(team, star)\n",
        "\n",
        "                    if data:\n",
        "                        resilience_map[team] = {\n",
        "                            \"star_out\": True,\n",
        "                            \"player\": star,\n",
        "                            \"status\": data['status'],\n",
        "                            \"resilience_score\": data['win_pct']\n",
        "                        }\n",
        "\n",
        "    print(\"‚úÖ Resilience Map Built.\")\n",
        "    return resilience_map"
      ],
      "metadata": {
        "id": "-aA983AO7fGt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nba_api.stats.static import teams\n",
        "from nba_api.stats.endpoints import leaguedashplayerstats\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def get_dynamic_star_rosters(teams_playing_list):\n",
        "    \"\"\"\n",
        "    Returns a dict of stars for teams playing tonight.\n",
        "    Structure: {'Los Angeles Lakers': ['Luka Doncic', 'LeBron James'], ...}\n",
        "    \"\"\"\n",
        "    print(\"\\nüìä CALCULATING PLAYER IMPACT (WAR)...\")\n",
        "\n",
        "    # 1. Fetch Season Stats\n",
        "    time.sleep(1) # Be polite to API\n",
        "    p_stats = leaguedashplayerstats.LeagueDashPlayerStats(season=SEASON).get_data_frames()[0]\n",
        "\n",
        "    # 2. Calculate Custom Impact Score (Your Formula)\n",
        "    p_stats['IMPACT'] = (\n",
        "        p_stats['PTS'] * 1.0 +\n",
        "        p_stats['REB'] * 1.2 +\n",
        "        p_stats['AST'] * 1.5 +\n",
        "        p_stats['STL'] * 2.0 +\n",
        "        p_stats['BLK'] * 2.0 -\n",
        "        p_stats['TOV'] * 1.5\n",
        "    ) / p_stats['GP']\n",
        "\n",
        "    # Normalize to 0-100 Scale\n",
        "    max_score = p_stats['IMPACT'].max()\n",
        "    p_stats['WAR'] = (p_stats['IMPACT'] / max_score) * 100\n",
        "\n",
        "    # 3. Create Mapping: Full Name -> Abbreviation (e.g. \"Los Angeles Lakers\" -> \"LAL\")\n",
        "    nba_teams = teams.get_teams()\n",
        "    team_map = {team['full_name']: team['abbreviation'] for team in nba_teams}\n",
        "\n",
        "    # Fix common CSV name mismatches\n",
        "    team_map['Los Angeles Clippers'] = 'LAC'\n",
        "    team_map['LA Clippers'] = 'LAC'\n",
        "\n",
        "    star_rosters = {}\n",
        "\n",
        "    # 4. Filter for tonight's teams\n",
        "    for team_name in teams_playing_list:\n",
        "        abbr = team_map.get(team_name)\n",
        "        if not abbr:\n",
        "            print(f\"‚ö†Ô∏è Warning: No abbreviation found for {team_name}\")\n",
        "            continue\n",
        "\n",
        "        # Get Top 3 Players by WAR for this team\n",
        "        roster = p_stats[p_stats['TEAM_ABBREVIATION'] == abbr].sort_values('WAR', ascending=False).head(3)\n",
        "\n",
        "        # Only count them as \"Stars\" if WAR > 65 (Filter out leaders of bad teams)\n",
        "        stars = roster[roster['WAR'] > 65]['PLAYER_NAME'].tolist()\n",
        "        star_rosters[team_name] = stars\n",
        "\n",
        "        if stars:\n",
        "            print(f\"   üåü {team_name} Stars: {', '.join(stars)}\")\n",
        "\n",
        "    return star_rosters"
      ],
      "metadata": {
        "id": "xywM0UwyDx3F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. PREDICT TONIGHT'S GAMES (FINAL V3.1)\n",
        "# ==========================================\n",
        "print(\"\\n=======================================================\")\n",
        "print(\"ü§ñ  INITIATING MODEL V3.1: DYNAMIC IMPACT ANALYSIS\")\n",
        "print(\"=======================================================\")\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# A. DYNAMIC STAR IDENTIFICATION\n",
        "# -------------------------------------------------------\n",
        "# 1. Get list of all teams playing tonight\n",
        "teams_tonight = pd.concat([predict_odds['Home Team'], predict_odds['Away Team']]).unique()\n",
        "\n",
        "# 2. Find out who the \"Stars\" are statistically right now\n",
        "STAR_ROSTERS = get_dynamic_star_rosters(teams_tonight)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# B. BUILD LIVE RESILIENCE MAP\n",
        "# -------------------------------------------------------\n",
        "# Now we update our builder to use STAR_ROSTERS instead of a hardcoded list\n",
        "def build_dynamic_resilience_map(games_df, star_rosters):\n",
        "    print(\"\\nüè• CHECKING INJURY STATUS OF IDENTIFIED STARS...\")\n",
        "    injuries = get_live_injury_report() # Your scraper function\n",
        "    resilience_map = {}\n",
        "\n",
        "    for _, row in games_df.iterrows():\n",
        "        for team in [row['Home Team'], row['Away Team']]:\n",
        "            stars = star_rosters.get(team, [])\n",
        "\n",
        "            for star in stars:\n",
        "                # Check if this specific star is OUT\n",
        "                if star in injuries:\n",
        "                    print(f\"‚ö†Ô∏è MATCH: {star} (WAR Leader) is {injuries[star]} for {team}\")\n",
        "\n",
        "                    # Run the \"Ewing Theory\" History Check\n",
        "                    # (Uses your calculate_team_resilience function)\n",
        "                    data = calculate_team_resilience(team, star)\n",
        "\n",
        "                    if data:\n",
        "                        resilience_map[team] = {\n",
        "                            \"star_out\": True,\n",
        "                            \"player\": star,\n",
        "                            \"status\": data['status'],\n",
        "                            \"resilience_score\": data['win_pct']\n",
        "                        }\n",
        "    return resilience_map\n",
        "\n",
        "# Build the map using the stars we just found\n",
        "LIVE_RESILIENCE_MAP = build_dynamic_resilience_map(predict_odds, STAR_ROSTERS)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# C. RUN PREDICTIONS\n",
        "# -------------------------------------------------------\n",
        "print(\"\\n--- üèÄ GENERATING PREDICTIONS ---\")\n",
        "print(f\"{'MATCHUP':<40} | {'SPREAD':<6} | {'SIGNAL':<25} | {'LOGIC'}\")\n",
        "print(\"-\" * 110)\n",
        "\n",
        "for _, row in predict_odds.iterrows():\n",
        "    home, away = row['Home Team'], row['Away Team']\n",
        "\n",
        "    # 1. Prepare Stats Input (LSTM)\n",
        "    home_stats = games[games['TEAM_NAME'] == home].sort_values('GAME_DATE').tail(SEQ_LENGTH)\n",
        "    input_seq = home_stats[features].values\n",
        "    input_seq = scaler.transform(input_seq).reshape(1, SEQ_LENGTH, len(features))\n",
        "    win_prob = model.predict(input_seq, verbose=0)[0][0]\n",
        "\n",
        "    # 2. Get Implied Spread\n",
        "    implied_spread = get_implied_spread(row['Home Odds'])\n",
        "\n",
        "    # 3. Apply Resilience Logic\n",
        "    signal = \"-- No Bet --\"\n",
        "    logic_note = f\"Model Prob: {win_prob:.2f}\"\n",
        "\n",
        "    # Check Home\n",
        "    if home in LIVE_RESILIENCE_MAP:\n",
        "        data = LIVE_RESILIENCE_MAP[home]\n",
        "        if data['status'] == 'Resilient':\n",
        "            signal = f\"üí∞ BET {home} (Value)\"\n",
        "            logic_note = f\"üíé 3-1 w/o {data['player']}\"\n",
        "        elif data['status'] == 'Dependent':\n",
        "            signal = f\"üìâ FADE {home}\"\n",
        "            logic_note = f\"‚ùå Needs {data['player']}\"\n",
        "\n",
        "    # Check Away\n",
        "    elif away in LIVE_RESILIENCE_MAP:\n",
        "        data = LIVE_RESILIENCE_MAP[away]\n",
        "        if data['status'] == 'Resilient':\n",
        "            signal = f\"üí∞ BET {away} (Value)\"\n",
        "            logic_note = f\"üíé {away} Resilient w/o {data['player']}\"\n",
        "        elif data['status'] == 'Dependent':\n",
        "            signal = f\"üìâ FADE {away}\"\n",
        "            logic_note = f\"‚ùå Needs {data['player']}\"\n",
        "\n",
        "    # 4. Standard Model Logic\n",
        "    if signal == \"-- No Bet --\":\n",
        "        if win_prob > 0.60: signal = f\"üî• BET {home}\"\n",
        "        elif win_prob < 0.40: signal = f\"üî• BET {away}\"\n",
        "        elif abs(implied_spread) > 14: signal = \"PASS\"\n",
        "\n",
        "    print(f\"{away} @ {home:<15} | {implied_spread:<6} | {signal:<25} | {logic_note}\")"
      ],
      "metadata": {
        "id": "B9QDLwGWEUqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 2. FETCH NBA STATS & FEATURE ENGINEERING\n",
        "# ==========================================\n",
        "print(f\"\\n--- STEP 2: Fetching {SEASON} Game Stats ---\")\n",
        "gamefinder = leaguegamefinder.LeagueGameFinder(\n",
        "    season_nullable=SEASON,\n",
        "    league_id_nullable='00',\n",
        "    season_type_nullable='Regular Season'\n",
        ")\n",
        "all_games = gamefinder.get_data_frames()[0]\n",
        "all_games['GAME_DATE'] = pd.to_datetime(all_games['GAME_DATE'])\n",
        "all_games = all_games.sort_values('GAME_DATE')\n",
        "all_games = all_games[all_games['WL'].notna()] # Remove games not played yet\n",
        "\n",
        "# --- CALCULATE \"FOUR FACTORS\" (Advanced Stats) ---\n",
        "# 1. Effective Field Goal % (Adjusts for 3-pointers)\n",
        "all_games['EFG_PCT'] = (all_games['FGM'] + 0.5 * all_games['FG3M']) / all_games['FGA']\n",
        "\n",
        "# 2. Turnover Rate (Turnovers per 100 possessions)\n",
        "# Estimate Possessions: FGA + 0.44*FTA - OREB + TOV\n",
        "all_games['POSS_EST'] = all_games['FGA'] + 0.44 * all_games['FTA'] - all_games['OREB'] + all_games['TOV']\n",
        "all_games['TOV_RATE'] = 100 * (all_games['TOV'] / all_games['POSS_EST'])\n",
        "\n",
        "# 3. Offensive Rebounding (Raw proxy since we lack opp stats in this view)\n",
        "all_games['OREB_RATE'] = all_games['OREB'] / all_games['POSS_EST'] # Proxy\n",
        "\n",
        "# 4. Free Throw Rate (Ability to draw fouls)\n",
        "all_games['FTA_RATE'] = all_games['FTA'] / all_games['FGA']\n",
        "\n",
        "# 5. Pace (Speed of play)\n",
        "all_games['PACE'] = 48 * (all_games['POSS_EST'] / (all_games['MIN'].astype(float) / 5))\n",
        "\n",
        "# Target Variable\n",
        "all_games['TARGET'] = all_games['WL'].apply(lambda x: 1 if x == 'W' else 0)\n",
        "\n",
        "print(\"‚úÖ Advanced Stats Calculated (Four Factors).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y88N88ldHDoi",
        "outputId": "6d0536ad-b20f-4a4b-f7ac-93db40293a1b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STEP 2: Fetching 2025-26 Game Stats ---\n",
            "‚úÖ Advanced Stats Calculated (Four Factors).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#==========================================\n",
        "# 3. MERGE API STATS WITH ODDS\n",
        "# ==========================================\n",
        "name_map = {\n",
        "    'LA Clippers': 'Los Angeles Clippers',\n",
        "    'L.A. Clippers': 'Los Angeles Clippers',\n",
        "    'L.A. Lakers': 'Los Angeles Lakers'\n",
        "}\n",
        "all_games['TEAM_NAME'] = all_games['TEAM_NAME'].replace(name_map)\n",
        "\n",
        "# Create Odds Lookup Table\n",
        "odds_lookup = pd.concat([\n",
        "    train_odds[['Date', 'Home Team', 'Home_Prob']].rename(columns={'Date':'GAME_DATE', 'Home Team':'TEAM_NAME', 'Home_Prob':'ODDS_PROB'}),\n",
        "    train_odds[['Date', 'Away Team', 'Away_Prob']].rename(columns={'Date':'GAME_DATE', 'Away Team':'TEAM_NAME', 'Away_Prob':'ODDS_PROB'})\n",
        "])\n",
        "\n",
        "# Merge\n",
        "merged_data = pd.merge(all_games, odds_lookup, on=['GAME_DATE', 'TEAM_NAME'], how='left')\n",
        "merged_data['ODDS_PROB'] = merged_data['ODDS_PROB'].fillna(0.5)\n",
        "\n",
        "# Define the V2 Feature Set\n",
        "features = [\n",
        "    'ODDS_PROB',    # Market Sentiment (Crucial)\n",
        "    'EFG_PCT',      # Shooting Efficiency\n",
        "    'TOV_RATE',     # Ball Security\n",
        "    'OREB_RATE',    # Rebounding\n",
        "    'FTA_RATE',     # Aggression\n",
        "    'PACE',         # Tempo\n",
        "    'PLUS_MINUS'    # Overall Dominance\n",
        "]"
      ],
      "metadata": {
        "id": "bOKxQAMyKcP7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. TRAIN LSTM MODEL (V3 ARCHITECTURE)\n",
        "# ==========================================\n",
        "print(\"\\n--- STEP 4: Training LSTM Neural Network ---\")\n",
        "\n",
        "# 1. Scale Data (0 to 1) for the Neural Network\n",
        "# We use the 'features' list you defined in Step 3\n",
        "scaler = MinMaxScaler()\n",
        "merged_data[features] = scaler.fit_transform(merged_data[features])\n",
        "\n",
        "# 2. Create Sequences (The \"Memory\" of the Model)\n",
        "# We feed the model the LAST 5 games to predict the NEXT game result\n",
        "X, y = [], []\n",
        "\n",
        "# Iterate through each unique team in the dataset\n",
        "for team_id in merged_data['TEAM_ID'].unique():\n",
        "    team_df = merged_data[merged_data['TEAM_ID'] == team_id].sort_values('GAME_DATE')\n",
        "\n",
        "    # Skip teams with insufficient data\n",
        "    if len(team_df) < SEQ_LENGTH + 1: continue\n",
        "\n",
        "    vals = team_df[features].values\n",
        "    # Convert 'W'/'L' to 1/0\n",
        "    targets = team_df['WL'].apply(lambda x: 1 if x == 'W' else 0).values\n",
        "\n",
        "    # Create sequences: Use 5 games (SEQ_LENGTH) to predict the 6th\n",
        "    for i in range(len(team_df) - SEQ_LENGTH):\n",
        "        X.append(vals[i:i+SEQ_LENGTH])      # Sequence of 5 games\n",
        "        y.append(targets[i+SEQ_LENGTH])     # Result of the 6th game\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# 3. Build LSTM Architecture (V3)\n",
        "# This is a Bidirectional LSTM which is more powerful than standard LSTM\n",
        "model = Sequential([\n",
        "    # Layer 1: Bidirectional LSTM\n",
        "    Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=regularizers.l2(0.01)),\n",
        "                  input_shape=(SEQ_LENGTH, len(features))),\n",
        "    Dropout(0.3), # Prevents overfitting\n",
        "\n",
        "    # Layer 2: Second LSTM Layer\n",
        "    Bidirectional(LSTM(32)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Layer 3: Output\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid') # Output: Probability (0 to 1)\n",
        "])\n",
        "\n",
        "# 4. Train the Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Verbose=0 keeps the output clean\n",
        "model.fit(X, y, epochs=30, batch_size=16, verbose=0)\n",
        "\n",
        "print(f\"‚úÖ Model Trained on {len(X)} historical game sequences.\")\n",
        "print(f\"‚úÖ Input Shape: {X.shape} (Samples, Time Steps, Features)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWk9JH5kKyCT",
        "outputId": "93768b79-63a0-4ba2-cd96-812f6adad6d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- STEP 4: Training LSTM Neural Network ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model Trained on 513 historical game sequences.\n",
            "‚úÖ Input Shape: (513, 5, 7) (Samples, Time Steps, Features)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. PREDICT TONIGHT'S GAMES (FINAL V3.1)\n",
        "# ==========================================\n",
        "print(\"\\n=======================================================\")\n",
        "print(\"ü§ñ  INITIATING MODEL V3.1: DYNAMIC IMPACT ANALYSIS\")\n",
        "print(\"=======================================================\")\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# A. DYNAMIC STAR IDENTIFICATION\n",
        "# -------------------------------------------------------\n",
        "# 1. Get list of all teams playing tonight\n",
        "teams_tonight = pd.concat([predict_odds['Home Team'], predict_odds['Away Team']]).unique()\n",
        "\n",
        "# 2. Find out who the \"Stars\" are statistically right now\n",
        "STAR_ROSTERS = get_dynamic_star_rosters(teams_tonight)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# B. BUILD LIVE RESILIENCE MAP\n",
        "# -------------------------------------------------------\n",
        "# Now we update our builder to use STAR_ROSTERS instead of a hardcoded list\n",
        "def build_dynamic_resilience_map(games_df, star_rosters):\n",
        "    print(\"\\nüè• CHECKING INJURY STATUS OF IDENTIFIED STARS...\")\n",
        "    injuries = get_live_injury_report() # Your scraper function\n",
        "    resilience_map = {}\n",
        "\n",
        "    for _, row in games_df.iterrows():\n",
        "        for team in [row['Home Team'], row['Away Team']]:\n",
        "            stars = star_rosters.get(team, [])\n",
        "\n",
        "            for star in stars:\n",
        "                # Check if this specific star is OUT\n",
        "                if star in injuries:\n",
        "                    print(f\"‚ö†Ô∏è MATCH: {star} (WAR Leader) is {injuries[star]} for {team}\")\n",
        "\n",
        "                    # Run the \"Ewing Theory\" History Check\n",
        "                    # (Uses your calculate_team_resilience function)\n",
        "                    data = calculate_team_resilience(team, star)\n",
        "\n",
        "                    if data:\n",
        "                        resilience_map[team] = {\n",
        "                            \"star_out\": True,\n",
        "                            \"player\": star,\n",
        "                            \"status\": data['status'],\n",
        "                            \"resilience_score\": data['win_pct']\n",
        "                        }\n",
        "    return resilience_map\n",
        "\n",
        "# Build the map using the stars we just found\n",
        "LIVE_RESILIENCE_MAP = build_dynamic_resilience_map(predict_odds, STAR_ROSTERS)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# C. RUN PREDICTIONS\n",
        "# -------------------------------------------------------\n",
        "print(\"\\n--- üèÄ GENERATING PREDICTIONS ---\")\n",
        "print(f\"{'MATCHUP':<40} | {'SPREAD':<6} | {'SIGNAL':<25} | {'LOGIC'}\")\n",
        "print(\"-\" * 110)\n",
        "\n",
        "for _, row in predict_odds.iterrows():\n",
        "    home, away = row['Home Team'], row['Away Team']\n",
        "\n",
        "    # 1. Prepare Stats Input (LSTM)\n",
        "    home_stats = games[games['TEAM_NAME'] == home].sort_values('GAME_DATE').tail(SEQ_LENGTH)\n",
        "    input_seq = home_stats[features].values\n",
        "    input_seq = scaler.transform(input_seq).reshape(1, SEQ_LENGTH, len(features))\n",
        "    win_prob = model.predict(input_seq, verbose=0)[0][0]\n",
        "\n",
        "    # 2. Get Implied Spread\n",
        "    implied_spread = get_implied_spread(row['Home Odds'])\n",
        "\n",
        "    # 3. Apply Resilience Logic\n",
        "    signal = \"-- No Bet --\"\n",
        "    logic_note = f\"Model Prob: {win_prob:.2f}\"\n",
        "\n",
        "    # Check Home\n",
        "    if home in LIVE_RESILIENCE_MAP:\n",
        "        data = LIVE_RESILIENCE_MAP[home]\n",
        "        if data['status'] == 'Resilient':\n",
        "            signal = f\"üí∞ BET {home} (Value)\"\n",
        "            logic_note = f\"üíé 3-1 w/o {data['player']}\"\n",
        "        elif data['status'] == 'Dependent':\n",
        "            signal = f\"üìâ FADE {home}\"\n",
        "            logic_note = f\"‚ùå Needs {data['player']}\"\n",
        "\n",
        "    # Check Away\n",
        "    elif away in LIVE_RESILIENCE_MAP:\n",
        "        data = LIVE_RESILIENCE_MAP[away]\n",
        "        if data['status'] == 'Resilient':\n",
        "            signal = f\"üí∞ BET {away} (Value)\"\n",
        "            logic_note = f\"üíé {away} Resilient w/o {data['player']}\"\n",
        "        elif data['status'] == 'Dependent':\n",
        "            signal = f\"üìâ FADE {away}\"\n",
        "            logic_note = f\"‚ùå Needs {data['player']}\"\n",
        "\n",
        "    # 4. Standard Model Logic\n",
        "    if signal == \"-- No Bet --\":\n",
        "        if win_prob > 0.60: signal = f\"üî• BET {home}\"\n",
        "        elif win_prob < 0.40: signal = f\"üî• BET {away}\"\n",
        "        elif abs(implied_spread) > 14: signal = \"PASS\"\n",
        "\n",
        "    print(f\"{away} @ {home:<15} | {implied_spread:<6} | {signal:<25} | {logic_note}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "JFaEPHp2LO_j",
        "outputId": "224a38fc-61bf-485e-d17e-dc27a51d1800"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=======================================================\n",
            "ü§ñ  INITIATING MODEL V3.1: DYNAMIC IMPACT ANALYSIS\n",
            "=======================================================\n",
            "\n",
            "üìä CALCULATING PLAYER IMPACT (WAR)...\n",
            "   üåü Boston Celtics Stars: Jaylen Brown\n",
            "   üåü Atlanta Hawks Stars: Jalen Johnson\n",
            "   üåü Cleveland Cavaliers Stars: Donovan Mitchell\n",
            "   üåü Detroit Pistons Stars: Cade Cunningham\n",
            "   üåü New York Knicks Stars: Karl-Anthony Towns, Jalen Brunson\n",
            "   üåü Chicago Bulls Stars: Josh Giddey\n",
            "   üåü Houston Rockets Stars: Alperen Sengun\n",
            "   üåü Milwaukee Bucks Stars: Giannis Antetokounmpo\n",
            "   üåü Oklahoma City Thunder Stars: Shai Gilgeous-Alexander\n",
            "   üåü Los Angeles Lakers Stars: Luka Donƒçiƒá, Austin Reaves\n",
            "   üåü Denver Nuggets Stars: Nikola Jokiƒá, Jamal Murray\n",
            "   üåü San Antonio Spurs Stars: Victor Wembanyama\n",
            "   üåü Portland Trail Blazers Stars: Deni Avdija\n",
            "   üåü Utah Jazz Stars: Lauri Markkanen\n",
            "   üåü Toronto Raptors Stars: Scottie Barnes\n",
            "   üåü Indiana Pacers Stars: Pascal Siakam\n",
            "   üåü Los Angeles Clippers Stars: James Harden\n",
            "   üåü Philadelphia 76ers Stars: Tyrese Maxey\n",
            "   üåü Dallas Mavericks Stars: Anthony Davis\n",
            "\n",
            "üè• CHECKING INJURY STATUS OF IDENTIFIED STARS...\n",
            "üè• Scrapping Live Injury Report...\n",
            "‚ùå Injury Scrape Failed: Length mismatch: Expected axis has 5 elements, new values have 3 elements\n",
            "\n",
            "--- üèÄ GENERATING PREDICTIONS ---\n",
            "MATCHUP                                  | SPREAD | SIGNAL                    | LOGIC\n",
            "--------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'games' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1096375243.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# 1. Prepare Stats Input (LSTM)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mhome_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TEAM_NAME'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhome\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GAME_DATE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhome_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'games' is not defined"
          ]
        }
      ]
    }
  ]
}